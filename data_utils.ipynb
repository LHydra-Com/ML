{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def preprocess_data(data):\n",
    "    # Handle missing values\n",
    "    data = handle_missing_values(data)\n",
    "\n",
    "    # Normalize or scale the features\n",
    "    data = normalize_features(data)\n",
    "\n",
    "    # Encode categorical variables\n",
    "    data = encode_categorical_variables(data)\n",
    "\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def handle_missing_values(data):\n",
    "    # Handle missing values based on your requirements\n",
    "    # For example, you can remove rows with missing values or fill them with a specific value\n",
    "    data = data.dropna()  # Remove rows with missing values\n",
    "    # data = data.fillna(0)  # Fill missing values with 0\n",
    "\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def normalize_features(data):\n",
    "    # Normalize or scale the features using MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    numerical_columns = ['plays', 'popularity', 'duration_ms']  # Update with the available numerical columns in your dataset\n",
    "\n",
    "    # Check if the numerical columns exist in the DataFrame\n",
    "    available_columns = [col for col in numerical_columns if col in data.columns]\n",
    "\n",
    "    if available_columns:\n",
    "        data[available_columns] = scaler.fit_transform(data[available_columns])\n",
    "\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def encode_categorical_variables(data):\n",
    "    # Encode categorical variables using LabelEncoder\n",
    "    categorical_columns = ['gender', 'country', 'artname']  # Update with the categorical columns in your dataset\n",
    "\n",
    "    # Check if the categorical columns exist in the DataFrame\n",
    "    available_columns = [col for col in categorical_columns if col in data.columns]\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    for column in available_columns:\n",
    "        data[column] = label_encoder.fit_transform(data[column])\n",
    "\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def extract_user_item_interactions(data):\n",
    "    # Extract user-item interactions from the dataset\n",
    "    user_item_interactions = data.groupby(['usersha1', 'artname'])['plays'].sum().unstack(fill_value=0)\n",
    "    return user_item_interactions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def extract_item_content_features(data):\n",
    "    # Extract item content features from the dataset\n",
    "    item_content_features = data.drop_duplicates(subset='artname')\n",
    "\n",
    "    # Define the desired columns for item content features\n",
    "    desired_columns = ['artname', 'genre', 'artist_popularity', 'danceability', 'energy', 'key', 'loudness', 'mode', \n",
    "                       'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "\n",
    "    # Check which desired columns are present in the DataFrame\n",
    "    available_columns = [col for col in desired_columns if col in item_content_features.columns]\n",
    "\n",
    "    # Select only the available columns\n",
    "    item_content_features = item_content_features[available_columns]\n",
    "\n",
    "    # Set 'artname' as the index\n",
    "    item_content_features = item_content_features.set_index('artname')\n",
    "\n",
    "    return item_content_features"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def split_data(user_item_interactions, n_splits=5, random_state=None):\n",
    "    # Get the user and item IDs\n",
    "    user_ids = user_item_interactions.index.tolist()\n",
    "    item_ids = user_item_interactions.columns.tolist()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Create a list of user-item pairs\n",
    "user_item_pairs = []\n",
    "for user_id in user_ids:\n",
    "    for item_id in item_ids:\n",
    "        user_item_pairs.append((user_id, item_id))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-10-298d6dacad8d>, line 3)",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[10], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    user_item_pairs = []\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create the interaction labels\n",
    "interaction_labels = [1 if user_item_interactions.loc[user_id, item_id] > 0 else 0\n",
    "                      for user_id, item_id in user_item_pairs]\n",
    "\n",
    "# Initialize the KFold object\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "# Initialize lists to store the train and test splits\n",
    "train_data_list = []\n",
    "test_data_list = []"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "",
     "evalue": "",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Perform cross-validation splits\n",
    "for train_indices, test_indices in kf.split(user_item_pairs):\n",
    "    # Get the train and test user-item pairs and interaction labels\n",
    "    train_pairs = [user_item_pairs[i] for i in train_indices]\n",
    "    test_pairs = [user_item_pairs[i] for i in test_indices]\n",
    "    train_labels = [interaction_labels[i] for i in train_indices]\n",
    "    test_labels = [interaction_labels[i] for i in test_indices]"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "",
     "evalue": "",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert the train and test pairs into DataFrames\n",
    "train_data = pd.DataFrame(train_pairs, columns=['user_id', 'item_id'])\n",
    "train_data['interaction'] = train_labels\n",
    "test_data = pd.DataFrame(test_pairs, columns=['user_id', 'item_id'])\n",
    "test_data['interaction'] = test_labels"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "",
     "evalue": "",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Append the train and test DataFrames to the respective lists\n",
    "train_data_list.append(train_data)\n",
    "test_data_list.append(test_data)\n",
    "\n",
    "    return train_data_list, test_data_list"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "",
     "evalue": "",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}